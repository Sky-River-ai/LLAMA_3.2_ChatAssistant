{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --quiet -U langchain langchain_community tiktoken langchain-nomic \"nomic[local]\" langchain-ollama scikit-learn langgraph tavily-python bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-nomic in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (0.1.3)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.2.40 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-nomic) (0.3.7)\n",
      "Requirement already satisfied: nomic<4.0.0,>=3.1.2 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-nomic) (3.1.2)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-nomic) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.2.40->langchain-nomic) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.2.40->langchain-nomic) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.2.40->langchain-nomic) (0.1.129)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.2.40->langchain-nomic) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.2.40->langchain-nomic) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.2.40->langchain-nomic) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<0.4,>=0.2.40->langchain-nomic) (4.12.2)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (8.1.7)\n",
      "Requirement already satisfied: jsonlines in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (0.7.2)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (13.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.32.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.2.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (4.66.5)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (17.0.0)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.40->langchain-nomic) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.40->langchain-nomic) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.40->langchain-nomic) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.2.40->langchain-nomic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.2.40->langchain-nomic) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from click->nomic<4.0.0,>=3.1.2->langchain-nomic) (0.4.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from jsonlines->nomic<4.0.0,>=3.1.2->langchain-nomic) (24.2.0)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from loguru->nomic<4.0.0,>=3.1.2->langchain-nomic) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2024.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from rich->nomic<4.0.0,>=3.1.2->langchain-nomic) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from rich->nomic<4.0.0,>=3.1.2->langchain-nomic) (2.18.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.40->langchain-nomic) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.40->langchain-nomic) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.40->langchain-nomic) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.40->langchain-nomic) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.1.2->langchain-nomic) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-nomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "import getpass\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3.2:1b-instruct-fp16\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0, format=\"json\")\n",
    "\n",
    "\n",
    "#we use Tavily, which is a search engine optimized for LLMs and RAG\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"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\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "\n",
    "urls = [\n",
    "    \"https://npousa.com/\",\n",
    "    \"https://npousa.com/solutions-services/\",\n",
    "    \"https://npousa.com/our-approach/\",\n",
    "    \"https://npousa.com/customers/\",\n",
    "    \"https://npousa.com/contact-us/?_gl=1*4cb6u6*_up*MQ..*_ga*NjcwMDk5MjY3LjE3Mjc4NDExMDk.*_ga_J5P9LNHH6S*MTcyNzg0MTEwOC4xLjAuMTcyNzg0MTEwOC4wLjAuMA..\"\n",
    "]\n",
    "\n",
    "# Load documents\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(k=3)\n",
    "\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPO USA offers a comprehensive suite of cloud solutions, including financial operations optimization (FinOps), DevOps strategies, cloud consulting (Cloud Advisor), seamless cloud migration journeys (Journey to Cloud), sophisticated cloud architecture design, advanced cloud automation, and efficient multi-cloud management. These services are designed to empower businesses across the globe with agility, scalability, and cost reduction. NPO USA's cloud solutions cater to various demands, providing a tailored approach that meets clients' needs in a consultative manner.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "question = \"What does NPO USA offer in cloud solutions?\"\n",
    "# Prompt\n",
    "rag_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "\n",
    "Here is the context to use to answer the question:\n",
    "\n",
    "{context} \n",
    "\n",
    "Think carefully about the above context. \n",
    "\n",
    "Now, review the user question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Provide an answer to this questions using only the above context. \n",
    "\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Test\n",
    "docs = retriever.invoke(question)\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "print(generation.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session started. You have 5 minutes.\n",
      "\n",
      "Answer: I am an assistant for question-answering tasks, providing information and answering inquiries based on the provided context.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession ended.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Running a 5-minute QA session\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[43mqa_session\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 49\u001b[0m, in \u001b[0;36mqa_session\u001b[1;34m(session_duration)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession started. You have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_duration\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m<\u001b[39m session_end_time:\n\u001b[1;32m---> 49\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mAsk a question: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m question\u001b[38;5;241m.\u001b[39mstrip():\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnding session as no question was provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\myenv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\myenv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Placeholder function to retrieve documents based on a question (use actual retriever logic)\n",
    "def retrieve_docs(question):\n",
    "    docs = retriever.invoke(question)  # Modify this based on your retrieval method\n",
    "    return format_docs(docs)\n",
    "\n",
    "# Formatting function to prepare context from documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Prompt structure\n",
    "rag_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "\n",
    "Here is the context to use to answer the question:\n",
    "\n",
    "{context} \n",
    "\n",
    "Think carefully about the above context. \n",
    "\n",
    "Now, review the user question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Provide an answer to this questions using only the above context. \n",
    "\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "# Function to handle a single question-answer cycle\n",
    "def get_answer(question, context=\"\"):\n",
    "    docs_txt = retrieve_docs(question)\n",
    "    updated_context = context + \"\\n\\n\" + docs_txt if context else docs_txt\n",
    "    rag_prompt_formatted = rag_prompt.format(context=updated_context, question=question)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "    return generation.content, updated_context\n",
    "\n",
    "# Main session loop\n",
    "def qa_session(session_duration=300):\n",
    "    context = \"\"\n",
    "    start_time = datetime.now()\n",
    "    session_end_time = start_time + timedelta(seconds=session_duration)\n",
    "    \n",
    "    print(f\"Session started. You have {session_duration // 60} minutes.\")\n",
    "\n",
    "    while datetime.now() < session_end_time:\n",
    "        question = input(\"\\nAsk a question: \")\n",
    "        if not question.strip():\n",
    "            print(\"Ending session as no question was provided.\")\n",
    "            break\n",
    "\n",
    "        answer, context = get_answer(question, context)\n",
    "        print(\"\\nAnswer:\", answer)\n",
    "\n",
    "    print(\"Session ended.\")\n",
    "\n",
    "# Running a 5-minute QA session\n",
    "qa_session(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m hallucination_bot_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mFACTS: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{documents}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m STUDENT ANSWER: \u001b[39m\u001b[38;5;132;01m{generation}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Test using documents and generation from above\u001b[39;00m\n\u001b[0;32m     17\u001b[0m hallucination_grader_prompt_formatted \u001b[38;5;241m=\u001b[39m hallucination_bot_prompt\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m---> 18\u001b[0m     documents\u001b[38;5;241m=\u001b[39m\u001b[43mdocs_txt\u001b[49m, generation\u001b[38;5;241m=\u001b[39mgeneration\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m result \u001b[38;5;241m=\u001b[39m llm_json_mode\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m     21\u001b[0m     [SystemMessage(content\u001b[38;5;241m=\u001b[39mhallucination_bot_instructions)]\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;241m+\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39mhallucination_grader_prompt_formatted)]\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m json\u001b[38;5;241m.\u001b[39mloads(result\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'docs_txt' is not defined"
     ]
    }
   ],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "# Hallucination grader instructions\n",
    "hallucination_bot_instructions = \"\"\"\n",
    "\n",
    "You are a Chatbot assistant who provides information to NPO USA Inc Website Visiters. \n",
    "You should not asssume anything.\n",
    "Make sure to give only information available on website.\n",
    "Do not add any extra information\n",
    "\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "hallucination_bot_prompt = \"\"\"FACTS: \\n\\n {documents} \\n\\n STUDENT ANSWER: {generation}. \n",
    "\n",
    "\"\"\"\n",
    "# Test using documents and generation from above\n",
    "docs_txt = retrieve_docs(question)\n",
    "hallucination_grader_prompt_formatted = hallucination_bot_prompt.format(\n",
    "    documents=docs_txt, generation=generation.content\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=hallucination_bot_instructions)]\n",
    "    + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
